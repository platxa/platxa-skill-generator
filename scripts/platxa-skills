#!/usr/bin/env python3
"""platxa-skills - Unified CLI for the Platxa Skills catalog.

Usage:
    platxa-skills validate <skill-directory> [--profile=strict|spec] [--verbose]
    platxa-skills score <skill-directory> [--json] [--threshold=N]
    platxa-skills install <name-or-path> [--user | --project] [--force]
    platxa-skills search <query>
    platxa-skills list [--category=CAT] [--json]
    platxa-skills init <name> [--type=TYPE]
    platxa-skills audit [--json] [--threshold=N] [--category=CAT]
"""

from __future__ import annotations

import argparse
import json
import shutil
import subprocess
import sys
import tempfile
from importlib.util import module_from_spec, spec_from_file_location
from pathlib import Path

SCRIPTS_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPTS_DIR.parent
SKILLS_DIR = PROJECT_ROOT / "skills"
CATALOG_REPO = "https://github.com/platxa/platxa-skill-generator.git"
SEARCH_INDEX_URL = "https://raw.githubusercontent.com/platxa/platxa-skill-generator/main/skills/search-index.json"
SEARCH_INDEX_CACHE = Path(tempfile.gettempdir()) / "platxa-search-index.json"
SEARCH_INDEX_CACHE_TTL = 3600  # 1 hour


def _run_script(script_name: str, args: list[str]) -> int:
    """Run a shell script from the scripts directory."""
    script = SCRIPTS_DIR / script_name
    if not script.exists():
        print(f"Error: {script_name} not found", file=sys.stderr)
        return 1
    result = subprocess.run([str(script), *args])
    return result.returncode


def _load_module(script_name: str) -> object:
    """Dynamically import a Python script from the scripts directory."""
    spec = spec_from_file_location(
        script_name.replace("-", "_").replace(".py", ""),
        SCRIPTS_DIR / script_name,
    )
    assert spec is not None and spec.loader is not None
    mod = module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod


def _run_security_check(skill_dir: Path) -> bool:
    """Run security-check.sh on a skill directory. Returns True if clean."""
    sec_script = SCRIPTS_DIR / "security-check.sh"
    if not sec_script.exists():
        return True
    try:
        result = subprocess.run(
            [str(sec_script), str(skill_dir)],
            capture_output=True,
            text=True,
            timeout=60,
        )
        return result.returncode == 0
    except (subprocess.TimeoutExpired, OSError):
        return False


def cmd_validate(args: argparse.Namespace) -> int:
    """Run all validators and scoring on a skill directory."""
    skill_dir = Path(args.skill_dir).resolve()
    if not skill_dir.is_dir():
        print(f"Error: Not a directory: {args.skill_dir}", file=sys.stderr)
        return 1

    # Phase 1: Run validate-all.sh (structure, frontmatter, tokens, security, duplicates)
    validate_script = SCRIPTS_DIR / "validate-all.sh"
    if not validate_script.exists():
        print("Error: validate-all.sh not found", file=sys.stderr)
        return 1

    validate_args = [str(validate_script), str(skill_dir)]
    if args.verbose:
        validate_args.append("--verbose")
    if args.profile:
        validate_args.append(f"--profile={args.profile}")

    validate_result = subprocess.run(validate_args)
    validation_passed = validate_result.returncode == 0

    # Phase 2: Run scoring + security check for accurate badge assignment
    score_mod = _load_module("score-skill.py")
    score_report = score_mod.score_skill(skill_dir)  # type: ignore[attr-defined]
    security_passed = _run_security_check(skill_dir)
    badge = score_mod.assign_badge(  # type: ignore[attr-defined]
        score_report["overall_score"], security_passed=security_passed
    )
    score_report["badge"] = badge

    threshold = args.threshold or 7.0
    score_passed = score_report["overall_score"] >= threshold

    # Phase 3: Combined report
    overall = score_report["overall_score"]

    if args.json:
        combined = {
            "skill_name": skill_dir.name,
            "validation_passed": validation_passed,
            "security_passed": security_passed,
            "score": score_report,
            "threshold": threshold,
            "overall_passed": validation_passed and score_passed,
        }
        print(json.dumps(combined, indent=2))
    else:
        print()
        print("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━")
        print("Quality Score")
        print("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━")
        print()

        for dim_name, dim_data in score_report["dimensions"].items():
            score = dim_data["score"]
            weight = dim_data["weight"]
            bar = "\u2588" * int(score) + "\u2591" * (10 - int(score))
            notes_str = ""
            if dim_data["notes"]:
                notes_str = f"  ({', '.join(dim_data['notes'][:2])})"
            print(f"  {dim_name:<14} {bar} {score:>4}/10  (w={weight}){notes_str}")

        print()
        print(f"  {'Overall':<14} {'':>10} {overall:>5}/10.0")
        print(f"  {'Badge':<14} {'':>10} {badge}")
        print()

        print("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━")
        if validation_passed and score_passed:
            print(f"PASSED — validation clean, score {overall}/10.0 ({badge})")
        elif not validation_passed:
            print(f"FAILED — validation errors (score {overall}/10.0)")
        else:
            print(f"FAILED — score {overall}/10.0 below threshold {threshold}")
        print("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━")

    return 0 if (validation_passed and score_passed) else 1


def cmd_score(args: argparse.Namespace) -> int:
    """Score a skill across quality dimensions."""
    script_args = [args.skill_dir]
    if args.json:
        script_args.append("--json")
    if args.threshold:
        script_args.extend(["--threshold", str(args.threshold)])
    return _run_script("score-skill.py", script_args)


def _fetch_skill_from_github(skill_name: str, target: Path) -> bool:
    """Fetch a skill from the GitHub catalog repo via sparse checkout."""
    with tempfile.TemporaryDirectory() as tmp:
        tmp_path = Path(tmp)
        result = subprocess.run(
            [
                "git",
                "clone",
                "--depth",
                "1",
                "--filter=blob:none",
                "--sparse",
                CATALOG_REPO,
                str(tmp_path / "repo"),
            ],
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            print(f"Error: Failed to clone catalog repo: {result.stderr}", file=sys.stderr)
            return False

        result = subprocess.run(
            [
                "git",
                "-C",
                str(tmp_path / "repo"),
                "sparse-checkout",
                "set",
                f"skills/{skill_name}",
            ],
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            print(f"Error: Failed to sparse-checkout skill: {result.stderr}", file=sys.stderr)
            return False

        source = tmp_path / "repo" / "skills" / skill_name
        if not (source / "SKILL.md").exists():
            print(f"Error: Skill '{skill_name}' not found in catalog repo", file=sys.stderr)
            return False

        if target.exists():
            shutil.rmtree(target)
        shutil.copytree(source, target)
        return True


def _install_from_directory(source: Path, target: Path) -> bool:
    """Copy a skill directory to the target location."""
    if not (source / "SKILL.md").exists():
        print(f"Error: No SKILL.md found in {source}", file=sys.stderr)
        return False
    if target.exists():
        shutil.rmtree(target)
    shutil.copytree(source, target)
    return True


def _resolve_skill_source(skill_ref: str) -> tuple[str, Path | None, str]:
    """Resolve a skill reference to (name, local_source_dir_or_None, label).

    Returns local_source=None when the skill must be fetched from GitHub.
    """
    ref_path = Path(skill_ref)
    if ref_path.is_dir() and (ref_path / "SKILL.md").exists():
        return ref_path.resolve().name, ref_path.resolve(), f"local path ({skill_ref})"

    catalog_path = SKILLS_DIR / skill_ref
    if catalog_path.is_dir() and (catalog_path / "SKILL.md").exists():
        return skill_ref, catalog_path, "local catalog"

    return skill_ref, None, f"GitHub ({CATALOG_REPO})"


def cmd_install(args: argparse.Namespace) -> int:
    """Install a skill by name (from catalog/GitHub) or by local path."""
    skill_name, local_source, source_label = _resolve_skill_source(args.skill)

    base = Path(".claude/skills") if args.project else Path.home() / ".claude" / "skills"
    target = base / skill_name

    if target.exists() and not args.force:
        print(f"Skill '{skill_name}' already installed at {target}")
        print("Use --force to overwrite.")
        return 1

    print(f"Installing '{skill_name}' from {source_label}")
    print(f"  Target: {target}")
    base.mkdir(parents=True, exist_ok=True)

    if local_source is not None:
        success = _install_from_directory(local_source, target)
    else:
        success = _fetch_skill_from_github(skill_name, target)

    if not success:
        return 1

    # Make scripts executable
    scripts_dir = target / "scripts"
    if scripts_dir.is_dir():
        for script in scripts_dir.iterdir():
            if script.suffix in (".sh", ".py"):
                script.chmod(script.stat().st_mode | 0o111)

    print(f"Installed '{skill_name}' to {target}")
    return 0


def _fetch_search_index_from_github() -> list[dict] | None:
    """Fetch search-index.json from GitHub with local caching."""
    import time
    import urllib.request

    # Check cache freshness
    if SEARCH_INDEX_CACHE.exists():
        age = time.time() - SEARCH_INDEX_CACHE.stat().st_mtime
        if age < SEARCH_INDEX_CACHE_TTL:
            try:
                return json.loads(SEARCH_INDEX_CACHE.read_text())
            except (json.JSONDecodeError, OSError):
                pass

    # Fetch from GitHub
    try:
        req = urllib.request.Request(SEARCH_INDEX_URL, headers={"User-Agent": "platxa-skills/1.0"})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = resp.read().decode()
        entries = json.loads(data)
        SEARCH_INDEX_CACHE.write_text(data)
        return entries
    except Exception:
        # Fall back to stale cache if available
        if SEARCH_INDEX_CACHE.exists():
            try:
                return json.loads(SEARCH_INDEX_CACHE.read_text())
            except (json.JSONDecodeError, OSError):
                pass
    return None


def cmd_search(args: argparse.Namespace) -> int:
    """Search skills by keyword with fuzzy matching."""
    search_path = SKILLS_DIR / "search-index.json"
    gen_mod = _load_module("generate-index.py")

    if search_path.exists():
        with open(search_path) as f:
            search_entries = json.load(f)
    else:
        # Try fetching from GitHub
        search_entries = _fetch_search_index_from_github()
        if search_entries is None:
            # Last resort: generate on-the-fly from local files
            index = gen_mod.generate_index(SKILLS_DIR)  # type: ignore[attr-defined]
            search_entries = gen_mod.generate_search_index(index)  # type: ignore[attr-defined]

    results = gen_mod.search_skills(search_entries, args.query)  # type: ignore[attr-defined]

    if not results:
        print(f"No skills matching '{args.query}'")
        return 0

    print(f"Found {len(results)} skill(s) matching '{args.query}':\n")
    for entry, score in results:
        desc = entry.get("description", "")[:80]
        cat = entry.get("category", "")
        print(f"  {entry['name']:<35} [{cat}]")
        print(f"    {desc}")
    return 0


def cmd_list(args: argparse.Namespace) -> int:
    """List all skills in the catalog."""
    index_path = SKILLS_DIR / "index.json"

    if not index_path.exists():
        gen_mod = _load_module("generate-index.py")
        index = gen_mod.generate_index(SKILLS_DIR)  # type: ignore[attr-defined]
    else:
        with open(index_path) as f:
            index = json.load(f)

    skills = index.get("skills", {})

    if args.category:
        skills = {k: v for k, v in skills.items() if v.get("category") == args.category}

    if args.json:
        print(json.dumps({"skills_count": len(skills), "skills": skills}, indent=2))
        return 0

    if not skills:
        print("No skills found.")
        return 0

    print(f"{'Skill':<35} {'Category':<15} {'Tokens':>6} {'Score':>6} {'Version':<10}")
    print("-" * 78)
    for name, info in sorted(skills.items()):
        cat = info.get("category", "")
        tokens = info.get("token_counts", {}).get("total", "?")
        sha = info.get("git_sha", info.get("sha", ""))
        version = info.get("version", sha[:7] if sha else "-")
        # Inline quality score from index if present, else compute
        score_val = info.get("quality_score", "")
        if not score_val:
            score_mod = _load_module("score-skill.py")
            skill_dir = SKILLS_DIR / name
            if skill_dir.is_dir():
                try:
                    report = score_mod.score_skill(skill_dir)  # type: ignore[attr-defined]
                    score_val = f"{report['overall_score']:.1f}"
                except Exception:
                    score_val = "?"
            else:
                score_val = "-"
        print(f"  {name:<33} {cat:<15} {tokens:>6} {score_val:>6} {version:<10}")

    print(f"\nTotal: {len(skills)} skills")
    return 0


SKILL_TYPES = {
    "builder": "Create artifacts (code, configs, documents)",
    "guide": "Teach/explain concepts with step-by-step instructions",
    "automation": "Automate repetitive tasks with triggers and scripts",
    "analyzer": "Inspect, audit, and report on code or systems",
    "validator": "Verify quality with rules, thresholds, and pass/fail",
}


def _prompt_skill_type() -> str:
    """Interactively prompt user to select a skill type."""
    print("Select skill type:\n")
    types = list(SKILL_TYPES.items())
    for i, (name, desc) in enumerate(types, 1):
        print(f"  {i}) {name:<14} — {desc}")
    print()

    while True:
        try:
            choice = input("Enter number [1-5]: ").strip()
        except (EOFError, KeyboardInterrupt):
            print()
            return "builder"
        if choice.isdigit() and 1 <= int(choice) <= len(types):
            selected = types[int(choice) - 1][0]
            print(f"  → {selected}\n")
            return selected
        print("  Invalid choice, try again.")


def cmd_init(args: argparse.Namespace) -> int:
    """Initialize a new skill from template."""
    skill_name = args.name
    skill_type = args.type

    # Interactive type selection when --type not explicitly provided
    if skill_type is None:
        if sys.stdin.isatty():
            skill_type = _prompt_skill_type()
        else:
            skill_type = "builder"

    # Validate name format
    if not all(c.isalnum() or c == "-" for c in skill_name):
        print(
            "Error: Skill name must be hyphen-case (lowercase letters, numbers, hyphens)",
            file=sys.stderr,
        )
        return 1

    target = Path(args.output) if args.output else SKILLS_DIR / skill_name
    if target.exists():
        print(f"Error: Directory already exists: {target}", file=sys.stderr)
        return 1

    # Create structure
    target.mkdir(parents=True)
    (target / "references").mkdir()

    # Write SKILL.md from template or minimal
    template_dir = PROJECT_ROOT / "references" / "templates" / skill_type
    if template_dir.exists():
        template_file = template_dir / "SKILL.md"
        if template_file.exists():
            content = template_file.read_text()
            content = content.replace("{{name}}", skill_name)
            (target / "SKILL.md").write_text(content)
            print(f"Created {target}/SKILL.md from {skill_type} template")
        else:
            _write_minimal_skill(target, skill_name)
    else:
        _write_minimal_skill(target, skill_name)

    print(f"\nSkill initialized: {target}")
    print(f"  Type: {skill_type}")
    print("\nNext steps:")
    print(f"  1. Edit {target}/SKILL.md with your skill content")
    print(f"  2. Add reference files to {target}/references/")
    print(f"  3. Run: platxa-skills validate {target}")
    return 0


def _write_minimal_skill(target: Path, skill_name: str) -> None:
    """Write a minimal SKILL.md scaffold."""
    (target / "SKILL.md").write_text(
        f"---\n"
        f"name: {skill_name}\n"
        f"description: TODO - describe what this skill does\n"
        f"---\n\n"
        f"# {skill_name.replace('-', ' ').title()}\n\n"
        f"## Overview\n\n"
        f"Describe the skill purpose and when to use it.\n\n"
        f"## Usage\n\n"
        f"Step-by-step instructions.\n"
    )
    print(f"Created {target}/SKILL.md (minimal scaffold)")


def cmd_audit(args: argparse.Namespace) -> int:
    """Run full audit across all catalog skills."""
    script_args: list[str] = []
    if args.json:
        script_args.append("--json")
    if args.threshold:
        script_args.extend(["--threshold", str(args.threshold)])
    if args.category:
        script_args.extend(["--category", args.category])
    return _run_script("audit-catalog.py", script_args)


def main() -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        prog="platxa-skills",
        description="Platxa Skills catalog CLI — validate, score, install, and manage Claude Code skills",
    )
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # validate
    p_validate = subparsers.add_parser(
        "validate", help="Run all validators and show score with badge"
    )
    p_validate.add_argument("skill_dir", help="Path to skill directory")
    p_validate.add_argument("-v", "--verbose", action="store_true", help="Show detailed output")
    p_validate.add_argument("--profile", choices=["strict", "spec"], help="Validation profile")
    p_validate.add_argument("--json", action="store_true", help="Output combined report as JSON")
    p_validate.add_argument("--threshold", type=float, help="Custom score threshold (default: 7.0)")

    # score
    p_score = subparsers.add_parser("score", help="Score a skill across quality dimensions")
    p_score.add_argument("skill_dir", help="Path to skill directory")
    p_score.add_argument("--json", action="store_true", help="Output as JSON")
    p_score.add_argument("--threshold", type=float, help="Custom pass threshold")

    # install
    p_install = subparsers.add_parser(
        "install", help="Install a skill by name (from catalog/GitHub) or local path"
    )
    p_install.add_argument("skill", help="Skill name or path to skill directory")
    p_install.add_argument(
        "--user", action="store_true", help="Install to ~/.claude/skills/ (default)"
    )
    p_install.add_argument("--project", action="store_true", help="Install to .claude/skills/")
    p_install.add_argument("--force", action="store_true", help="Overwrite existing installation")

    # search
    p_search = subparsers.add_parser("search", help="Search skills by keyword")
    p_search.add_argument("query", help="Search query")

    # list
    p_list = subparsers.add_parser("list", help="List all skills in the catalog")
    p_list.add_argument("--category", help="Filter by category")
    p_list.add_argument("--json", action="store_true", help="Output as JSON")

    # init
    p_init = subparsers.add_parser("init", help="Initialize a new skill from template")
    p_init.add_argument("name", help="Skill name (hyphen-case)")
    p_init.add_argument(
        "--type",
        default=None,
        choices=["builder", "guide", "automation", "analyzer", "validator"],
        help="Skill type template (interactive prompt if omitted)",
    )
    p_init.add_argument("-o", "--output", help="Output directory (default: skills/<name>)")

    # audit
    p_audit = subparsers.add_parser("audit", help="Run full audit across all catalog skills")
    p_audit.add_argument("--json", action="store_true", help="Output as JSON")
    p_audit.add_argument("--threshold", type=float, help="Custom pass threshold")
    p_audit.add_argument("--category", help="Filter by category")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    commands = {
        "validate": cmd_validate,
        "score": cmd_score,
        "install": cmd_install,
        "search": cmd_search,
        "list": cmd_list,
        "init": cmd_init,
        "audit": cmd_audit,
    }

    return commands[args.command](args)


if __name__ == "__main__":
    sys.exit(main())
