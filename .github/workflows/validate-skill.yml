name: Validate Skills

on:
  pull_request:
    paths:
      - 'skills/**'
      - 'scripts/**'
      - '.claude-plugin/**'
  push:
    paths:
      - 'skills/**'
      - 'scripts/**'
      - '.claude-plugin/**'
    branches:
      - main

permissions:
  contents: read
  pull-requests: write

jobs:
  validate-skills:
    name: Validate Skills
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install tiktoken pyyaml

      - name: Make scripts executable
        run: |
          chmod +x scripts/*.sh

      - name: Get changed skills
        id: changed-skills
        run: |
          ALL_SKILLS=$(python3 -c "
          import yaml
          with open('skills/manifest.yaml') as f:
              m = yaml.safe_load(f)
          print(' '.join(m.get('skills', {}).keys()))
          ")

          if [ "${{ github.event_name }}" == "pull_request" ]; then
            TOUCHED=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | grep "^skills/" | cut -d'/' -f2 | sort -u)
            CHANGED=""
            for t in $TOUCHED; do
              if echo " $ALL_SKILLS " | grep -q " $t "; then
                CHANGED="$CHANGED $t"
              fi
            done
            CHANGED=$(echo "$CHANGED" | xargs)
          else
            CHANGED=""
            for s in $ALL_SKILLS; do
              if [ -d "skills/$s" ]; then
                CHANGED="$CHANGED $s"
              fi
            done
            CHANGED=$(echo "$CHANGED" | xargs)
          fi

          echo "skills=$CHANGED" >> $GITHUB_OUTPUT
          echo "Changed skills: $CHANGED"

      - name: Validate changed skills
        id: validate
        run: |
          SKILLS="${{ steps.changed-skills.outputs.skills }}"
          FAILED=0

          # Initialize report file with table header
          {
            echo "## Skills Validation Report"
            echo ""
            echo "| Skill | Profile | Validation | Tokens | Budget | Duplicates | Security | Score | Badge |"
            echo "|-------|---------|------------|--------|--------|------------|----------|-------|-------|"
          } > /tmp/validation-report.md

          if [ -z "$SKILLS" ]; then
            echo "No skills to validate"
            echo "report=No skills changed in this PR." >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          get_profile() {
            local skill_name="$1"
            python3 -c "
          import yaml
          with open('skills/manifest.yaml') as f:
              m = yaml.safe_load(f)
          skill = m.get('skills', {}).get('$skill_name', {})
          if skill.get('local', False):
              print('strict')
          else:
              print('spec')
          "
          }

          : > /tmp/score-details.md

          for skill in $SKILLS; do
            SKILL_DIR="skills/$skill"
            if [ ! -d "$SKILL_DIR" ]; then
              continue
            fi

            PROFILE=$(get_profile "$skill")

            # Run validation and capture output
            VALIDATION_OUTPUT=$(./scripts/validate-all.sh "$SKILL_DIR" --profile="$PROFILE" 2>&1) || true
            VALIDATION_EXIT=$?

            # Get token count
            TOKEN_OUTPUT=$(python3 scripts/count-tokens.py "$SKILL_DIR" --json 2>&1) || true
            TOTAL_TOKENS=$(echo "$TOKEN_OUTPUT" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d['total_tokens'])" 2>/dev/null || echo "?")
            TOKEN_PASSED=$(echo "$TOKEN_OUTPUT" | python3 -c "import sys,json; d=json.load(sys.stdin); print('yes' if d['passed'] else 'no')" 2>/dev/null || echo "?")

            # Run duplicate check
            DUP_OUTPUT=$(python3 scripts/check-duplicates.py "$SKILL_DIR" 2>&1) || true
            DUP_EXIT=$?

            # Run security check
            SEC_OUTPUT=$(./scripts/security-check.sh "$SKILL_DIR" 2>&1) || true
            SEC_EXIT=$?

            # Run quality scoring and badge assignment
            SCORE_OUTPUT=$(python3 -c "
          import sys
          sys.path.insert(0, 'scripts')
          from importlib.util import spec_from_file_location, module_from_spec
          spec = spec_from_file_location('sm', 'scripts/score-skill.py')
          mod = module_from_spec(spec)
          spec.loader.exec_module(mod)
          from pathlib import Path
          report = mod.score_skill(Path('$SKILL_DIR'))
          sec = True if $SEC_EXIT == 0 else False
          badge = mod.assign_badge(report['overall_score'], security_passed=sec)
          dims = report['dimensions']
          print(f'{report[\"overall_score\"]:.1f}')
          print(badge)
          for d, v in dims.items():
              print(f'{d}:{v[\"score\"]:.1f}:{v[\"weight\"]}')
          " 2>/dev/null) || true

            QUALITY_SCORE=$(echo "$SCORE_OUTPUT" | head -1)
            BADGE=$(echo "$SCORE_OUTPUT" | sed -n '2p')

            if [ -z "$QUALITY_SCORE" ]; then
              QUALITY_SCORE="?"
              BADGE="?"
            fi

            # Build per-skill score breakdown (write to file to avoid YAML escaping issues)
            DIM_LINES=$(echo "$SCORE_OUTPUT" | tail -n +3)
            if [ -n "$DIM_LINES" ]; then
              {
                echo "<details><summary><b>${skill}</b> — ${QUALITY_SCORE}/10.0 (${BADGE})</summary>"
                echo ""
                echo "| Dimension | Score | Weight |"
                echo "|-----------|-------|--------|"
                while IFS=: read -r dim_name dim_score dim_weight; do
                  echo "| ${dim_name} | ${dim_score}/10 | ${dim_weight} |"
                done <<< "$DIM_LINES"
                echo ""
                echo "</details>"
              } >> /tmp/score-details.md
            fi

            # Build per-skill report
            if [ $VALIDATION_EXIT -eq 0 ]; then
              STATUS="✅ passed"
            elif [ "$PROFILE" = "spec" ]; then
              STATUS="⚠️ warning (external)"
            else
              STATUS="❌ failed"
              FAILED=1
            fi

            if [ "$DUP_EXIT" -ne 0 ]; then
              DUP_STATUS="❌ duplicate found"
              FAILED=1
            else
              DUP_STATUS="✅ unique"
            fi

            if [ "$SEC_EXIT" -ne 0 ]; then
              SEC_STATUS="❌ issues found"
              FAILED=1
            else
              SEC_STATUS="✅ clean"
            fi

            echo "| \`${skill}\` | ${PROFILE} | ${STATUS} | ${TOTAL_TOKENS} | ${TOKEN_PASSED} | ${DUP_STATUS} | ${SEC_STATUS} | ${QUALITY_SCORE} | ${BADGE} |" >> /tmp/validation-report.md
          done

          if [ -s /tmp/score-details.md ]; then
            echo "" >> /tmp/validation-report.md
            echo "### Quality Score Breakdown" >> /tmp/validation-report.md
            cat /tmp/score-details.md >> /tmp/validation-report.md
          fi

          if [ $FAILED -eq 1 ]; then
            echo "" >> /tmp/validation-report.md
            echo "### ❌ Validation FAILED" >> /tmp/validation-report.md
            echo "One or more local skills failed strict validation. Please fix the issues and push again." >> /tmp/validation-report.md
          else
            echo "" >> /tmp/validation-report.md
            echo "### ✅ All validations passed" >> /tmp/validation-report.md
          fi

          echo "failed=$FAILED" >> $GITHUB_OUTPUT

          # Also print to CI log
          cat /tmp/validation-report.md

          if [ $FAILED -eq 1 ]; then
            exit 1
          fi

      - name: Comment validation report on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body;
            try {
              body = fs.readFileSync('/tmp/validation-report.md', 'utf8').trim();
            } catch {
              body = '## Skills Validation Report\n\nNo validation output generated.';
            }

            // Find existing bot comment to update
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const marker = '## Skills Validation Report';
            const existing = comments.data.find(c =>
              c.user.type === 'Bot' && c.body.includes(marker)
            );

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body: body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body,
              });
            }

      - name: Submit PR review
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const failed = '${{ steps.validate.outputs.failed }}' === '1';

            // Dismiss any previous bot review before submitting a new one
            const reviews = await github.rest.pulls.listReviews({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
            });
            for (const r of reviews.data) {
              if (r.user.type === 'Bot' && (r.state === 'APPROVED' || r.state === 'CHANGES_REQUESTED')) {
                try {
                  await github.rest.pulls.dismissReview({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    pull_number: context.issue.number,
                    review_id: r.id,
                    message: 'Superseded by new validation run.',
                  });
                } catch { /* ignore if dismiss fails */ }
              }
            }

            const event = failed ? 'REQUEST_CHANGES' : 'APPROVE';
            const reviewBody = failed
              ? 'Skill validation failed. Please fix the issues listed in the validation report above.'
              : 'All skill validations passed. Quality scores and badges look good.';

            await github.rest.pulls.createReview({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              event: event,
              body: reviewBody,
            });

  validate-structure:
    name: Validate Registry Structure
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pyyaml

      - name: Check skills README is updated
        if: github.event_name == 'pull_request'
        run: |
          NEW_SKILLS=$(git diff --name-only --diff-filter=A ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | grep "^skills/.*/SKILL.md" | cut -d'/' -f2)

          if [ -n "$NEW_SKILLS" ]; then
            echo "New skills detected: $NEW_SKILLS"
            echo ""
            echo "Checking if skills/README.md mentions new skills..."

            for skill in $NEW_SKILLS; do
              if ! grep -q "$skill" skills/README.md; then
                echo "⚠️  Warning: $skill not found in skills/README.md"
                echo "Please update the skills README to include your new skill."
              else
                echo "✓ $skill found in skills/README.md"
              fi
            done
          fi

      - name: Verify skill directory structure
        run: |
          echo "Verifying skill directory structure..."

          SKILLS=$(python3 -c "
          import yaml
          with open('skills/manifest.yaml') as f:
              m = yaml.safe_load(f)
          print(' '.join(m.get('skills', {}).keys()))
          ")

          for skill in $SKILLS; do
            skill_dir="skills/$skill"

            if [ ! -d "$skill_dir" ]; then
              echo "⊘ $skill: No directory (external, not yet synced)"
              continue
            fi

            if [ ! -f "$skill_dir/SKILL.md" ]; then
              echo "✗ $skill: Missing SKILL.md"
              exit 1
            fi

            if ! head -1 "$skill_dir/SKILL.md" | grep -q "^---"; then
              echo "✗ $skill: SKILL.md missing YAML frontmatter"
              exit 1
            fi

            echo "✓ $skill: Structure valid"
          done

          echo ""
          echo "All skill directories have valid structure."

      - name: Validate frontmatter on all skills
        run: |
          echo "Validating SKILL.md frontmatter for all skills..."
          chmod +x scripts/validate-frontmatter.sh

          SKILLS=$(python3 -c "
          import yaml
          with open('skills/manifest.yaml') as f:
              m = yaml.safe_load(f)
          print(' '.join(m.get('skills', {}).keys()))
          ")

          FAILED=0
          for skill in $SKILLS; do
            skill_dir="skills/$skill"
            if [ ! -d "$skill_dir" ]; then
              continue
            fi

            if ! ./scripts/validate-frontmatter.sh "$skill_dir" > /dev/null 2>&1; then
              echo "✗ $skill: Frontmatter validation failed"
              ./scripts/validate-frontmatter.sh "$skill_dir" 2>&1 | grep -E "ERROR" || true
              FAILED=1
            else
              echo "✓ $skill: Frontmatter valid"
            fi
          done

          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "Some skills have invalid frontmatter. Fix errors above."
            exit 1
          fi

          echo ""
          echo "All skills pass frontmatter validation."
